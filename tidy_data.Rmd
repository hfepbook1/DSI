---
title: "Tidy data and relational datasets"
output:
  html_document: 
    toc: true
    toc_float: true
---

The overarching goal of data wrangling is to have a tidy, easy-to-use dataset. 

This is the third module in the [Data Wrangling I](topic_data_wrangling_i.html) topic; the relevant slack channel is [here](https://p8105-fall2017.slack.com/messages/C75HFE38U).

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```

## Some slides

<script async class="speakerdeck-embed" data-id="77a37cf3dcb945a9abd2e09439158d07" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"></script>
<div style="margin-bottom:5px"> <strong> <a href="https://speakerdeck.com/jeffgoldsmith/dsi-tidy-data" title="Tidy Data" target="_blank">Tidy Data</a> </strong> from <strong><a href="https://speakerdeck.com/jeffgoldsmith" target="_blank">Jeff Goldsmith</a></strong>. </div><br>


## Example

I'll keep using the same R Project as in [data import](data_import.html) and [data manipulation](data_manipulation.html), but create a new .Rmd for tidying. I'm also going to load some relevant packages, and limit the number of lines printed in a tibble.

```{r}
library(tidyverse)
library(haven)
library(readxl)
library(janitor)

options(tibble.print_min = 5)
```

### `gather`

In [data import](data_import.html), we used the `haven` package to load the PULSE biomarkers dataset from a .sas7bdat. Let's reload those data and take a closer look:
```{r}
pulse_data = read_sas("./data/public_pulse_data.sas7bdat") %>%
  clean_names()
pulse_data
```

With our new understanding of tidy data, we quickly recognize a problem: the BDI score is spread across four columns, which correspond to four observation times. We can fix this problem using `gather`:
```{r}
pulse_tidy_data = gather(pulse_data, key = visit, value = bdi, bdiscore_bl:bdiscore_12m)
pulse_tidy_data
```

This looks much better! However, you should notice that this produced a warning. The warning seemed pretty specific but I didn't understand it, so I googled "tidyr gather attributes are not identical across measure variables; they will be dropped" and found [this](https://stackoverflow.com/questions/28972386/retain-attributes-when-using-gather-from-tidyr-attributes-are-not-identical). After some reading (and maybe a bit more googling), it started to sound like the columns containing BDI scores had different attributes, and indeed they do:
```{r}
str(pulse_data)
```
Each BDI score column has a specific label in the SAS dataset; these don't match, so `gather` dropped them when creating the `bdi` column. Not a problem here, but dropping attributes could be an issue if you wanted to preserve dates, factors, or some other feature. 

### `separate`

The other issue with the PULSE data, now, is `visit`. The original column names were informative but are not necessarily the format we would need for analysis. I'm going to split `visit` into two columns using `separate`:

```{r}
separate(pulse_tidy_data, visit, into = c("remove", "visit"), sep = "_")
```

This isn't really the optimal way to isolate "visit" because I now need an additional `select` step to remove the unnecessary character variable `remove`. However, it does illustrate the `separate` function, and we haven't yet learned about `str_replace` and other functions from the `stringr` package that are better suited to this problem, so ...

In the preceding I've saved intermediate datasets to make each step clear. While this can be a helpful crutch as you're trying out code, it is generally bad practice. There are also some additional transformations needed to wrap up the data wrangling process, like changing `bl` to `00m` for consistency across visits and converting `visit` to a factor variable. (It's possible that you would want `visit` to be a numeric variable instead, which could be done with a different call to `mutate`.) Lastly, it's nice to organize the data into a reasonable order.

Altogether, then, the code below will import, tidy, and transform the PULSE dataset into a usable format:
```{r}
pulse_data = read_sas("./data/public_pulse_data.sas7bdat") %>%
  clean_names() %>%
  gather(key = visit, value = bdi, bdiscore_bl:bdiscore_12m) %>%
  separate(visit, into = c("remove", "visit"), sep = "_") %>%
  select(id, visit, everything(), -remove) %>%
  mutate(visit = replace(visit, visit == "bl", "00m"),
         visit = factor(visit, levels = paste0(c("00", "01", "06", "12"), "m"))) %>%
  arrange(id, visit)

print(pulse_data, n = 12)
```

Before moving on, let's revisit the `group` variable in the litters dataset: 
```{r}
read_csv("./data/FAS_litters.csv", col_types = "ccddiiii") %>% 
  clean_names() %>%
  pull(group) %>%
  table()
```

These data are also untidy: `group` encodes both dose and day of treatment! Time to fix that ...
```{r}
litters_data = 
  read_csv("./data/FAS_litters.csv", col_types = "ccddiiii") %>% 
  clean_names() %>%
  separate(group, into = c("dose", "day_of_tx"), sep = 3) %>%
  mutate(dose = tolower(dose),
         wt_gain = gd18_weight - gd0_weight) %>%
  arrange(litter_number)

litters_data
```

Now we're in pretty good shape :-).

### `spread`

We've been exclusively interested in tidying data, but we've admitted that sometimes untidy is better for human consumption. For that reason we're going to take a short digression into untidying your tidy data.

The code below creates a tidy dataset that could result from an analysis. This is the correct format for additional analysis or visualization, but doesn't facilitate quick comparisons for human readers.
```{r}
analysis_result = tibble(
  group = c("treatment", "treatment", "placebo", "placebo"),
  time = c("pre", "post", "pre", "post"),
  mean = c(4, 8, 3.5, 4)
)

analysis_result
```

An alternative presentation of the same data might have groups in rows, times in columns, and mean values in table cells. This is decidedly non-tidy; to get there from here we'll need to use `spread`, which is the inverse of `gather`:
```{r}
spread(analysis_result, key = time, value = mean)
```

We're pretty much there now, although you could use `select` to reorder columns, and (depending on your goal) use `knitr::kable()` to produce a nicer table for reading.


### Binding rows

We've looked at single-table non-tidy data, but non-tidiness often stems from relevant data spread across multiple tables. In the simplest case, these tables are basically the same and can be stacked to produce a tidy dataset. That's the setting in `LotR_words.xlsx`, where the word counts for different races and sexes in each movie in the trilogy are spread across distinct data rectangles (these data are based on [this example](https://github.com/jennybc/lotr-tidy/blob/master/01-intro.md)).

To produce the desired tidy dataset, we first need to read each table and do some cleaning.
```{r}
fellowship_ring = read_excel("./data/LotR_Words.xlsx", range = "B3:D6") %>%
  clean_names() %>%
  gather(key = sex, value = words, female:male) %>%
  mutate(race = tolower(race),
         movie = "Fellowship")

two_towers = read_excel("./data/LotR_Words.xlsx", range = "F3:H6") %>%
  clean_names() %>%
  gather(key = sex, value = words, female:male) %>%
  mutate(race = tolower(race),
         movie = "Two Towers")

return_king = read_excel("./data/LotR_Words.xlsx", range = "J3:L6") %>%
  clean_names() %>%
  gather(key = sex, value = words, female:male) %>%
  mutate(race = tolower(race),
         movie = "Return")
```

This illustrates that there's often some work needed to ensure the separate tables can be reasonably stacked. As an aside, the three code snippets above are all basically the same except for the range and the movie name -- later we'll see a better way to handle cases like this by writing our own functions, but this works for now.

Once each table is ready to go, we can stack them up using `bind_rows`:
```{r}
lotr_tidy = bind_rows(fellowship_ring, two_towers, return_king) %>%
  select(movie, everything()) 

lotr_tidy
```

Having the data in this form will make it easier to make comparisons across movies, aggregate within races across the trilogy, and perform other analyses. 

### Joining datasets

Data can be spread across multiple related tables, in which case it is necessary to combine or **join** them prior to analysis. We'll focus on the problem of combining two tables only; combining three or more is done step-by-step using the same ideas. 

There are four major ways join dataframes `x` and `y`:

* Inner: keeps data that appear in both `x` and `y`
* Left: keeps data that appear in `x`
* Right: keeps data that appear in `y`
* Full: keeps data that appear in either `x` or `y`

Left joins are the most common, because they add data from a smaller table `y` into a larger table `x` without removing anything from `x`. 

As an example, consider the data tables in `FAS_pups.csv` and `FAS_litters.csv`, which are related through the `Litter Number` variable. The former contains data unique to each pup, and the latter contains data unique to each litter. We can combine these using a left join of litter data into pup data; doing so retains data on each pup and adds data in new columns.

```{r}
pup_data = read_csv("./data/FAS_pups.csv", col_types = "ciiiii") %>%
  clean_names() %>%
  mutate(sex = recode(sex, `1` = "male", `2` = "female")) 

litter_data = read_csv("./data/FAS_litters.csv", col_types = "ccddiiii") %>%
  clean_names %>%
  select(-pups_survive) %>%
  mutate(
    wt_gain = gd18_weight - gd0_weight,
    group = tolower(group))

FAS_data = left_join(pup_data, litter_data, by = "litter_number")
FAS_data
```

We made the key explicit in the join. By default, the `*_join` functions in `dplyr` will try to determine the key(s) based on variable names in the datasets you want to join. This is often but not always sufficient, and an extra step to make the key clear will help you and others reading your code.

Note that joining is not particularly amenable to the `%>%` operator because it is fundamentally non-linear: two separate datasets are coming together, rather than a single dataset being processed in a step-by-step fashion.

As a final point, the `*_join` functions are very much related to SQL syntax, but emphasize operations common to data analysis. 

## Other materials

* R for Data Science, of course, has a chapter on [tidy data](http://r4ds.had.co.nz/tidy-data.html). The [paper](http://www.jstatsoft.org/v59/i10/paper) that lays out the underlying ideas may also be useful.
* R for Data Science also has an excellent and very detailed presentation of [joins](http://r4ds.had.co.nz/relational-data.html).
* Jenny Bryan's [Stat 545](http://stat545.com) class has content on tidy data -- parts [1](https://github.com/jennybc/lotr-tidy/blob/master/01-intro.md), [2](https://github.com/jennybc/lotr-tidy/blob/master/02-gather.md),
[3](https://github.com/jennybc/lotr-tidy/blob/master/03-spread.md), and [4](https://github.com/jennybc/lotr-tidy/blob/master/04-tidy-bonus-content.md) are all good (some of the content above is very much related to this).
* You should revisit the data import [cheatsheet](https://github.com/rstudio/cheatsheets/raw/master/source/pdfs/data-import-cheatsheet.pdf), which also has some tips for tidying.


