---
title: "Strings and factors"
output:
  html_document: 
    toc: true
    toc_float: true
---

Most of the tools we examined in [Data Wrangling I](topic_data_wrangling_i.html) were general purpose things -- what tidy data is, using `dplyr` and `tidyr` for manipulation of data tables. Two variable types, strings and factors, present enough challenges to examine in some detail. Now might also be a good time to read up on the [history](https://simplystatistics.org/2015/07/24/stringsasfactors-an-unauthorized-biography/) of strings and factors in R!

This is the second module in the [Data Wrangling II](topic_data_wrangling_ii.html) topic; the relevant slack channel is [here](https://p8105-fall2017.slack.com/messages/C7N8HG34N).

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```


## Some slides

<script async class="speakerdeck-embed" data-id="bfb454627b71408889958f0893413097" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"></script>
<div style="margin-bottom:5px"> <strong> <a href="https://speakerdeck.com/jeffgoldsmith/dsi-strings-and-factors" title="Strings and Factors" target="_blank">Strings and Factors</a> </strong> from <strong><a href="https://speakerdeck.com/jeffgoldsmith" target="_blank">Jeff Goldsmith</a></strong>. </div><br>


## Example

I'll write code for today's content in a new R Markdown document called `strings_and_factors.Rmd`, and put it in the same directory / GitHub repo as `reading_data_from_the_web.Rmd`. I'm also going to load the usual packages, as well as `stringr` and `forcats`.

```{r}
library(tidyverse)
library(janitor)
library(haven)
library(rvest)

library(stringr)
library(forcats)

theme_set(theme_bw())
theme_update(legend.position = "bottom")
```

### Pups data

We'll start by revisiting a dataset we've seen a few times, now. In [tidy data](tidy_data.html) we spent some time tidying the pups dataset; as part of that we used tools available to us at the time, but now we have some better tools. 

The code below updates the data processing pipeline for the pups data using `strignr` and `forcats`. The result is the same, and the differences are pretty small, but this is a bit cleaner. 

```{r}
pulse_data = read_sas("./data/public_pulse_data.sas7bdat") %>%
  clean_names() %>%
  gather(key = visit, value = bdi, bdiscore_bl:bdiscore_12m) %>%
  mutate(visit = str_replace(visit, "bdiscore_", ""),
         visit = str_replace(visit, "bl", "00m"),
         visit = fct_relevel(visit, str_c(c("00", "01", "06", "12"), "m"))) %>%
  arrange(id, visit)

print(pulse_data, n = 12)
```


### NSDUH

Next we'll revisit the table scraped from the National Survey on Drug Use and Health data on [this page](http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm). In [reading data from the web](reading_data_from_the_web.html), we loaded this data using the code below, but noted it wasn't tidy. 

```{r}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"
drug_use_xml = read_html(url)

table_marj = (drug_use_xml %>% html_nodes(css = "table"))[[1]] %>%
  html_table() %>%
  .[-1,] %>%
  as_tibble()
```

There are a few steps we need to implement to tidy these data. For now I'm not interested in the p-values (I'd rather just see the data); we also have age groups and year ranges in column titles, both of which are, in fact, variables. Lastly, the table includes letters as superscripts next to table entries; if we only want the percents we'll need to strip these out. 

```{r}
data_marj = 
  table_marj %>%
  select(-contains("P Value")) %>%
  gather(key = key, value = percent, -State) %>%
  separate(key, into = c("age", "year"), sep = "\\(") %>%
  mutate(year = str_sub(year, 1, -2),
         percent = str_replace(percent, "[a-z]", ""),
         percent = as.numeric(percent)) %>%
  filter(!(State %in% c("Total U.S.", "Northeast", "Midwest", "South", "West")))
```

We used `stringr` and regular expressions a couple of times above:

* in `separate`, we split age and year at the open parentheses using `"\\("`
* to remove character superscripts, we replaced any character using `"[a-z]"`

Let's quickly visualize these data for the 12-17 age group; to make the plot readable, we'll treat `State` as a factor are reorder according to `percent`. 

```{r}
data_marj %>%
  filter(age == "12-17") %>% 
  mutate(State = fct_reorder(State, percent)) %>% 
  ggplot(aes(x = State, y = percent, color = year)) + 
    geom_point() + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


### Toothbrush reviews

We were able to scrape toothbrush reviews for a single review page in [reading data from the web](reading_data_from_the_web.html). If we want to scrape more reviews, it's necessary to construct the URLs for several review pages. This is possible based on an observation about the the structure of the URL for the [first page](https://www.amazon.com/Philips-Sonicare-rechargeable-toothbrush-HX6211/product-reviews/B00YAR7ZFM/ref=cm_cr_arp_d_viewopt_srt?ie=UTF8&reviewerType=all_reviews&sortBy=recent&pageNumber=1) of reviews -- it ended with `pageNumber=1` and, sure enough, changing this to `pageNumber=2` will bring up the [second page](https://www.amazon.com/Philips-Sonicare-rechargeable-toothbrush-HX6211/product-reviews/B00YAR7ZFM/ref=cm_cr_arp_d_viewopt_srt?ie=UTF8&reviewerType=all_reviews&sortBy=recent&pageNumber=2) of reviews. 

```{r}
url_base = "https://www.amazon.com/Philips-Sonicare-rechargeable-toothbrush-HX6211/product-reviews/B00YAR7ZFM/ref=cm_cr_arp_d_viewopt_srt?ie=UTF8&reviewerType=all_reviews&sortBy=recent&pageNumber="

urls = str_c(url_base, 1:5)

read_html(urls[1]) %>% 
  html_nodes("#cm_cr-review_list .review-title") %>%
  html_text()

read_html(urls[2]) %>% 
  html_nodes("#cm_cr-review_list .review-title") %>%
  html_text()
```

It would get really tedious to try to scrape all (5000+) reviews by copying code over and over; before long we'll learn about writing R functions to reuse code and make this much easier!


### Restaurant inspections

As a final example of strings and factors, we'll take a look at the [NYC Restuarant Inspections](dataset_restaurant_inspections.Rmd) data. Although we won't talk about this in detail now, it's worth mentioning that these data were collected using the NYC Open Data API; code is available with the data description.

First we'll import the data and take a look.

```{r}
nyc_inspections = read_csv("./data/DOHMH_New_York_City_Restaurant_Inspection_Results.csv.gz")

nyc_inspections %>% 
  group_by(boro, grade) %>% 
  summarize(n = n()) %>% 
  spread(key = grade, value = n)
```

To simplify things, I'll remove inspections with scores other than `A`, `B`, or `C`, and also remove the restaurants with missing boro information. I'll also clean up boro names a bit.

```{r}
nyc_inspections =
  nyc_inspections %>%
  filter(grade %in% c("A", "B", "C"), boro != "Missing") %>% 
  mutate(boro = str_to_title(boro))
```

Let's focus only on pizza places for now, and re-examine grades by boro

```{r}
nyc_inspections %>% 
  filter(str_detect(dba, "Pizza")) %>% 
  group_by(boro, grade) %>% 
  summarize(n = n()) %>% 
  spread(key = grade, value = n)
```

That doesn't look right -- for sure there are more pizza places than that! The problem is that the match in `str_detect` is case-sensitive until we tell it not to be:

```{r}
nyc_inspections %>% 
  filter(str_detect(dba, regex("pizza", ignore_case = TRUE))) %>% 
  group_by(boro, grade) %>% 
  summarize(n = n()) %>% 
  spread(key = grade, value = n)
```

The table is okay but I'd like to visualize this. 

```{r}
nyc_inspections %>% 
  filter(str_detect(dba, regex("pizza", ignore_case = TRUE))) %>%
  ggplot(aes(x = boro, fill = grade)) + geom_bar()
```

Might help to have things in a different order -- maybe number of pizza places? Fortunately this can be done using `fct_infreq`. 

```{r}
nyc_inspections %>% 
  filter(str_detect(dba, regex("pizza", ignore_case = TRUE))) %>%
  mutate(boro = fct_infreq(boro)) %>%
  ggplot(aes(x = boro, fill = grade)) + geom_bar()
```

Suppose I want to rename a boro; I'll try to do this using `replace`.

```{r}
nyc_inspections %>% 
  filter(str_detect(dba, regex("pizza", ignore_case = TRUE))) %>%
  mutate(boro = fct_infreq(boro),
         boro = replace(boro, which(boro == "Brooklyn"), "Hipsterville")) %>%
  ggplot(aes(x = boro, fill = grade)) + geom_bar()
```

That didn't work at all! Factors have very specific values, trying to use a value that is not an existing factor level won't work. Fortunately there is a dedicated function for renaming factor levels:

```{r}
nyc_inspections %>% 
  filter(str_detect(dba, regex("pizza", ignore_case = TRUE))) %>%
  mutate(boro = fct_infreq(boro),
         boro = fct_recode(boro, "Hipsterville" = "Brooklyn")) %>%
  ggplot(aes(x = boro, fill = grade)) + geom_bar()
```

Success!


## Other materials

* R for Data Science has chapters on both [strings](http://r4ds.had.co.nz/strings.html) and [factors](http://r4ds.had.co.nz/factors.html)
* There are useful materials by Jenny Bryan on [strings](http://stat545.com/block022_regular-expression.html) and [factors](http://stat545.com/block029_factors.html) as well

The code that I produced working examples in lecture is [here]().
